<!DOCTYPE html>
<html>
  <head>
    <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">
    <link rel="stylesheet" href="/assets/css/style.css">
    <link rel="stylesheet" href="/assets/css/markdown.css">
    <link rel="stylesheet" href="/assets/css/header.css">
    <link rel="icon" href="/assets/images/favicon.ico">
    
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/highlight.min.js"></script>
  </head>
  <body>
    <header>
      <div class="container">
        <div class="header-left">
          <a href="/index" class="header-logo"><img class="logo" src="/assets/images/kei.png"></a>
          <a href="/index" class="header-name">軸屋敬介 | Keisuke Jikuya</a>
        </div>
        <div class="header-right">
          <a id="sun_moon" class="fa fa-moon-o" onclick="dark_btn()"></a>
          <script src="/assets/js/darkmode.js"></script>
          <a href="/index">Home</a>
          <a href="/blogs">Blog</a>
          <a href="/notes">Note</a>
          <a href="/posts">Post</a>
        </div>
      </div>
    </header>
    <!DOCTYPE html>
<html>
  <title>Egocentric Human-Object Interaction Detection Exploiting Synthetic Data</title>
  <head>
    <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">
    <link rel="stylesheet" href="/assets/css/style.css">
    <script>
  MathJax = {
    tex: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      processEscapes: true,
      tags: "ams",
      autoload: {
        color: [],
        colorV2: ['color']
      },
      packages: {'[+]': ['noerrors']}
    },
    chtml: {
      matchFontHeight: false,
      displayAlign: "left",
      displayIndent: "2em"
    },
    options: {
      renderActions: {
        /* add a new named action to render <script type="math/tex"> */
        find_script_mathtex: [10, function (doc) {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/);
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
            const text = document.createTextNode('');
            node.parentNode.replaceChild(text, node);
            math.start = {node: text, delim: '', n: 0};
            math.end = {node: text, delim: '', n: 0};
            doc.math.push(math);
          }
        }, '']
      }
    },
    loader: {
      load: ['[tex]/noerrors']
    }
  };
</script>
<script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" id="MathJax-script"></script>
  </head>
  <body>
    <img src="/assets/images/posts/EgocentricHOI/5.png" class="hero">
    <h1>Egocentric Human-Object Interaction Detection Exploiting Synthetic Data</h1>
    <p><span class="fa fa-link"></span><a href="https://iplab.dmi.unict.it/EHOI_SYNTH/" target="_blank"> https://iplab.dmi.unict.it/EHOI_SYNTH/</a></p>
    <p><span class="fa fa-calendar"></span> Sep 5, 2022</p>
    <p><span class="fa fa-flag"></span> Human-Object Interaction Detection, Dataset, </p>
    <p><span class="fa fa-graduation-cap"></span> arXiv (2022) </p>
    <div class="share-btn-wrapper">
      <a href="https://twitter.com/share?text=Egocentric Human-Object Interaction Detection Exploiting Synthetic Data&url=https://absolute-value.github.io/hoi/2022/09/05/EgocentricHOI.html" class="share-btn share-twitter"><span class="fa fa-twitter fa-2x"></span></a>
      <a href="https://www.facebook.com/sharer.php?u=https://absolute-value.github.io/hoi/2022/09/05/EgocentricHOI.html" class="share-btn share-facebook"><span class="fa fa-facebook fa-2x"></span></a>
      <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://absolute-value.github.io/hoi/2022/09/05/EgocentricHOI.html&title=Egocentric Human-Object Interaction Detection Exploiting Synthetic Data" class="share-btn"><span class="fa fa-linkedin fa-2x"></span></a>
      <a href="mailto:?subject=Egocentric Human-Object Interaction Detection Exploiting Synthetic Data&body=Egocentric Human-Object Interaction Detection Exploiting Synthetic Data https://absolute-value.github.io/hoi/2022/09/05/EgocentricHOI.html" class="share-btn share-email"><span class="fa fa-envelope fa-2x"></span></a>
    </div>
    <h1 id="概要">概要</h1>

<p>産業環境（電気基板のテストおよび修理作業）においてHOI検出を行う際に、大量のデータの収集・ラベリングは困難である。そこで、自動的にラベリングされた合成一人称画像を生成するパイプラインとツールを提案する。生成した合成データで事前学習をし、実データでファインチューニングをすることで、実データでのHOI検出の性能を向上させた。
<!--more--></p>

<h1 id="新規性差分">新規性・差分</h1>

<ul>
  <li>産業界を対象とした手と物体のラベルやセグメンテーションを含む、HOI検出用の合成一人称データセットを提示</li>
  <li>Understanding human hands in contact at internet scale (CVPR 2020)を全ての物体を検出できるように拡張した手法を提案</li>
  <li>合成データの有用性を実験でベースライン手法と比較</li>
</ul>

<h1 id="アイデア">アイデア</h1>

<ul>
  <li>合成データの作成
    <ul>
      <li><img src="/assets/images/posts/EgocentricHOI/1.png" alt="" /></li>
      <li>3Dスキャナ(対象物：Artec Eva 5, 環境：MatterPort 6)を用いて物体や環境の3Dモデルを取得</li>
      <li>3Dモデルから、RGB画像・深度マップ・セグメンテーション・物体のBBとカテゴリ・手のBBとオブジェクトとの接触状態を生成するツールをBlenderで作成した
        <ul>
          <li><img src="/assets/images/posts/EgocentricHOI/2.png" alt="" /></li>
          <li>カメラ位置・照明 ・手の色など、仮想シーンをカスタマイズして自動撮影することも可能</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>実データの作成
    <ul>
      <li>7人の被験者の工業用実験室での電気基板の試験・修理作業を8本、Microsoft Hololens 2を用いて撮影し、手動でアノテーション</li>
      <li>操作をMRで指示（操作に一貫性を持たせ、自然に行うため）</li>
    </ul>
  </li>
  <li>HOI検出手法
    <ul>
      <li><img src="/assets/images/posts/EgocentricHOI/3.png" alt="" /></li>
      <li>Understanding human hands in contact at internet scale (CVPR 2020)を基本に、画像中の全ての物体を検出するようにした
        <ul>
          <li>Faster RCNNベースの手法</li>
          <li>ResNet101がBackbone</li>
          <li><img src="/assets/images/posts/EgocentricHOI/4.png" alt="" /></li>
        </ul>
      </li>
      <li>Hand side classification module
        <ul>
          <li>左右の手のどちらかを予測</li>
        </ul>
      </li>
      <li>Hand state classification module
        <ul>
          <li>手が物体と接触しているかを予測</li>
        </ul>
      </li>
      <li>Offset vector regression module
        <ul>
          <li>手のBBと物体のBBの中心をリンクさせるOffset vectorを予測</li>
        </ul>
      </li>
      <li>RGB 画像から、物体のカテゴリ・手の側面・手の接触状態・HOIを&lt;手、 接触状態、アクティブ物体、<他の物体>&gt;の4重項として推論</他の物体></li>
    </ul>
  </li>
</ul>

<h1 id="結果">結果</h1>

<p><img src="/assets/images/posts/EgocentricHOI/5.png" alt="" /></p>

<ul>
  <li>物体検出性能
    <ul>
      <li><img src="/assets/images/posts/EgocentricHOI/6.png" alt="" /></li>
      <li>事前学習にSynthetic（合成データ）を使用し、実データ50%でファインチューニングした結果が1位</li>
      <li>事前学習にSynthetic（合成データ）を使用し、実データ100%でファインチューニングした結果が2位</li>
    </ul>
  </li>
  <li>HOI検出性能（データ配分比較）
    <ul>
      <li>
        <p><img src="/assets/images/posts/EgocentricHOI/7.png" alt="" /></p>
      </li>
      <li>
        <p>事前学習にSynthetic（合成データ）を使用し、実データ100%でファインチューニングした結果がほとんどで1位</p>
      </li>
    </ul>
  </li>
  <li>HOI検出性能（既存手法との比較）
    <ul>
      <li><img src="/assets/images/posts/EgocentricHOI/8.png" alt="" /></li>
      <li>物体には強いが、合成データの手のリアリティが低いためか性能が低い
        <ul>
          <li>BS1：単一オブジェクト</li>
          <li>BS2：実データからのサンプリング画像</li>
          <li>BS3：合成データ</li>
          <li>BS4：合成データと実データ両方</li>
          <li>BS5：YOLOv5でラベリング</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

    <div class="btn-wrapper">
      <a href="/posts" class="btn back_btn">一覧へ戻る</a>
    </div>
  </body>
</html>
    <footer>
      <div class="btn-wrapper">
        <a href="mailto:jikuya[at]cv.info.gifu-u.ac.jp" class="bottom-btn email"><i class="fa fa-envelope fa-2x"></i></a>
        <a href="https://twitter.com/jky_kei" class="bottom-btn twitter" target="_blank"><i class="fa fa-twitter fa-2x"></i></a>
        <a href="https://github.com/Absolute-Value" class="bottom-btn github" target="_blank"><i class="fa fa-github fa-2x"></i></a>
      </div>
      <div class="container">
        <p>Copyright © 2022 - 2023 Keisuke JIKUYA</p>
      </div>
    </footer>
  </body>
</html>