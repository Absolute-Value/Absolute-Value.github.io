<!DOCTYPE html>
<html>
  <head>
    <script src="https://kit.fontawesome.com/314069a903.js" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="/assets/css/style.css">
    <link rel="stylesheet" href="/assets/css/markdown.css">
    <link rel="stylesheet" href="/assets/css/header.css">
    <link rel="icon" href="/assets/images/favicon.ico">
    
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/highlight.min.js"></script>
  </head>
  <body>
    <header>
      <div class="container">
        <div class="header-left">
          <a href="/index" class="header-logo"><img class="logo" src="/assets/images/kei.png"></a>
          <a href="/index" class="header-name">軸屋敬介 | Keisuke Jikuya</a>
        </div>
        <div class="header-right">
          <a id="sun_moon" class="fa fa-moon-o" onclick="dark_btn()"></a>
          <script src="/assets/js/darkmode.js"></script>
          <a href="/index">Home</a>
          <a href="/blogs">Blog</a>
          <a href="/notes">Note</a>
          <a href="/posts">Post</a>
        </div>
      </div>
    </header>
    <!DOCTYPE html>
<html>
  <head>
    <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">
    <link rel="stylesheet" href="/assets/css/style.css">
  </head>
  <body>
    <div class="top-wrapper">
      <div class="container">
        <h1>Posts</h1>
        <p>読んだ論文をまとめておく場所です</p>
      </div>
    </div>
    <!DOCTYPE html>
<html>
  <title>Posts</title>
  <head>
    <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">
    <link rel="stylesheet" href="/assets/css/posts.css">
    <script>
  MathJax = {
    tex: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      processEscapes: true,
      tags: "ams",
      autoload: {
        color: [],
        colorV2: ['color']
      },
      packages: {'[+]': ['noerrors']}
    },
    chtml: {
      matchFontHeight: false,
      displayAlign: "left",
      displayIndent: "2em"
    },
    options: {
      renderActions: {
        /* add a new named action to render <script type="math/tex"> */
        find_script_mathtex: [10, function (doc) {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/);
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
            const text = document.createTextNode('');
            node.parentNode.replaceChild(text, node);
            math.start = {node: text, delim: '', n: 0};
            math.end = {node: text, delim: '', n: 0};
            doc.math.push(math);
          }
        }, '']
      }
    },
    loader: {
      load: ['[tex]/noerrors']
    }
  };
</script>
<script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" id="MathJax-script"></script>
  </head>
  <body>
    
    <div class="myposts">
      
        
        <div class="post">
          <a href="/transformer/2024/03/28/ReConPatch.html">
            <img class="post_img" src="/assets/images/posts/ReConPatch/1.png">
            <div class="post_detail"> 
              <p><b>ReConPatch : Contrastive Patch Representation Learning for Industrial Anomaly Detection</b></p>
              <p class="post_p"><h1 id=""></h1>

<ul>
  <li>既存手法では、自然画像データセットから事前に学習した視覚表現を活用しているため、産業データセットへの適用にはギャップが存在</li>
  <li>事前学習モデルからのパッチ特徴の線形変調を訓練し、コントラスト表現学習を用いて異常検出のための識別的特徴を構築</li>
  <li>MVTec ADデータセットおよびBTADデータセットにおける最先端の異常検出性能</li>
</ul>
</p>
              <p>
                <span class="fa fa-calendar"></span> Mar 28, 2024
                <span class="fa fa-folder"></span> Transformer
                <span class="fa fa-graduation-cap"></span> WACV (2024)
              </p>
            </div>
          </a>
        </div>
        
      
        
        <div class="post">
          <a href="/transformer/2024/02/15/Unified-IO2.html">
            <img class="post_img" src="/assets/images/posts/Unified-IO2/1.png">
            <div class="post_detail"> 
              <p><b>Unified-IO 2: Scaling Autoregressive Multimodal Models with Vision, Language, Audio, and Action</b></p>
              <p class="post_p"><h1 id=""></h1>

<ul>
  <li>マルチモーダルモデルUNIFIED-IO 2を提案</li>
  <li>異なるモダリティを統合するために、入出力をトークン化し、単一のEncoder Decoder Transformerモデルで意味空間を共有</li>
  <li>モデルトレーニングの安定化のためにさまざまなアーキテクチャ改善</li>
  <li>GRITベンチマークで最先端の性能を達成し、画像生成と理解、自然言語理解、ビデオとオーディオの理解、ロボット操作を含む35以上のベンチマークで強力な結果を達成</li>
</ul>
</p>
              <p>
                <span class="fa fa-calendar"></span> Feb 15, 2024
                <span class="fa fa-folder"></span> Transformer
                <span class="fa fa-graduation-cap"></span> arXiv (2023)
              </p>
            </div>
          </a>
        </div>
        
      
        
        <div class="post">
          <a href="/dataset/2024/02/15/VideoSwin.html">
            <img class="post_img" src="/assets/images/posts/VideoSwin/3.png">
            <div class="post_detail"> 
              <p><b>Video Swin Transformer</b></p>
              <p class="post_p"><h1 id=""></h1>

<ul>
  <li>既存のビデオモデルは、空間的・時間的次元にわたってパッチをグローバルに接続するTransformer Layerを使用</li>
  <li>提案ビデオアーキテクチャは局所性の帰納バイアスを持ち、従来のアプローチに比べて速度と精度のトレードオフを改善</li>
  <li>小さな事前学習データセットとモデルサイズを使用しながらも、Kinetics-400とKinetics-600とSomething-Something v2でSoTA</li>
</ul>
</p>
              <p>
                <span class="fa fa-calendar"></span> Feb 15, 2024
                <span class="fa fa-folder"></span> Dataset
                <span class="fa fa-graduation-cap"></span> CVPR (2022)
              </p>
            </div>
          </a>
        </div>
        
      
        
        <div class="post">
          <a href="/transformer/2023/10/23/MusicTransformer.html">
            <img class="post_img" src="/assets/images/posts/MusicTransformer/0.png">
            <div class="post_detail"> 
              <p><b>Music Transformer: Generating music with long-term structure</b></p>
              <p class="post_p"><h1 id=""></h1>

<ul>
  <li>音楽の長期構造を生成するためのMusic Transformerを提案</li>
  <li>Music Transformerは既存のTransformerモデルの相対位置情報の表現を改善し、音楽の相対的なタイミングとピッチを捉えることができる</li>
  <li>データセット「JSB Chorales」と「Piano-e-Competition」で評価され、後者で最先端の結果を達成</li>
</ul>
</p>
              <p>
                <span class="fa fa-calendar"></span> Oct 23, 2023
                <span class="fa fa-folder"></span> Transformer
                <span class="fa fa-graduation-cap"></span> ICLR (2019)
              </p>
            </div>
          </a>
        </div>
        
      
        
        <div class="post">
          <a href="/dataset/2023/10/23/Places.html">
            <img class="post_img" src="/assets/images/posts/Places/0.png">
            <div class="post_detail"> 
              <p><b>Places: An Image Database for Deep Scene Understanding</b></p>
              <p class="post_p"><h1 id=""></h1>

<ul>
  <li>シーンの意味論的なカテゴリと属性がラベル付けされた 1,000 万枚のシーン写真のリポジトリである Places Databaseについて説明</li>
  <li>最先端のCNNを使用して分類時に優れたベースラインパフォーマンス</li>
</ul>
</p>
              <p>
                <span class="fa fa-calendar"></span> Oct 23, 2023
                <span class="fa fa-folder"></span> Dataset
                <span class="fa fa-graduation-cap"></span> IEEE (2018)
              </p>
            </div>
          </a>
        </div>
        
      
        
        <div class="post">
          <a href="/dataset/2023/10/22/sun397.html">
            <img class="post_img" src="/assets/images/posts/sun397/0.png">
            <div class="post_detail"> 
              <p><b>Sun database: Large-scale scene recognition from abbey to zoo</b></p>
              <p class="post_p"><h1 id=""></h1>

<ul>
  <li>899のカテゴリと130,519の画像を含む広範なScene UNderstanding (SUN) データベースを提案</li>
  <li>さまざまな最先端のアルゴリズムを使用してシーン認識の新しいパフォーマンスの境界を設定</li>
</ul>
</p>
              <p>
                <span class="fa fa-calendar"></span> Oct 22, 2023
                <span class="fa fa-folder"></span> Dataset
                <span class="fa fa-graduation-cap"></span> CVPR (2010)
              </p>
            </div>
          </a>
        </div>
        
      
        
        <div class="post">
          <a href="/transformer/2023/10/16/BEIT.html">
            <img class="post_img" src="/assets/images/posts/BEIT/0.png">
            <div class="post_detail"> 
              <p><b>BEIT: BERT Pre-Training of Image Transformers</b></p>
              <p class="post_p"><h1 id=""></h1>

<ul>
  <li>Vision Transformer事前学習する自己教師ありタスクを提案</li>
  <li>BERTのようなマスク画像モデリングを行う</li>
  <li>画像分類とセマンティックセグメンテーションで競争力のある結果を達成し、事前トレーニング方法を改善</li>
</ul>
</p>
              <p>
                <span class="fa fa-calendar"></span> Oct 16, 2023
                <span class="fa fa-folder"></span> Transformer
                <span class="fa fa-graduation-cap"></span> ICLR (2022)
              </p>
            </div>
          </a>
        </div>
        
      
        
        <div class="post">
          <a href="/caption/2023/07/03/RedCaps.html">
            <img class="post_img" src="/assets/images/posts/RedCaps/1.png">
            <div class="post_detail"> 
              <p><b>RedCaps: Web-curated image-text data created by the people, for the people</b></p>
              <p class="post_p"><h1 id=""></h1>

<ul>
  <li>ビジョンと言語のタスクのための大規模データセットは、検索エンジンをクエリにしたりHTMLのaltテキストを収集することで構築されているが、ウェブデータはノイズが多いため、品質を維持するために複雑なフィルタリングパイプラインが必要</li>
  <li>最小限のフィルタリングで高品質なデータを収集するための代替データソースを探索</li>
  <li>Redditから収集された1200万の画像とキャプションのペアのRedCapsという大規模なデータセットを紹介</li>
</ul>
</p>
              <p>
                <span class="fa fa-calendar"></span> Jul 3, 2023
                <span class="fa fa-folder"></span> Caption
                <span class="fa fa-graduation-cap"></span> NeurIPS (2021)
              </p>
            </div>
          </a>
        </div>
        
      
    </div>
    
    <div class="btn-wrapper">
      
      
      <a href="/posts/2/" class="btn back_btn next">></a>
      <a href="/posts/9/" class="btn back_btn previous">>>></a>
      
    
    </div>
  </body>
</html>
  </body>
</html>
    <footer>
      <div class="btn-wrapper">
        <a href="mailto:jikuya[at]cv.info.gifu-u.ac.jp" class="bottom-btn email"><i class="fa fa-envelope fa-2x"></i></a>
        <a href="https://twitter.com/jky_kei" class="bottom-btn twitter" target="_blank"><i class="fa-brands fa-x-twitter fa-2x"></i></a>
        <a href="https://github.com/Absolute-Value" class="bottom-btn github" target="_blank"><i class="fa fa-github fa-2x"></i></a>
      </div>
      <div class="container">
        <p>Copyright © 2022 - 2023 Keisuke JIKUYA</p>
      </div>
    </footer>
  </body>
</html>